---
title: 'SDK Reference'
description: 'Complete Python SDK reference for Delve'
---

## Installation

```bash
pip install delve-taxonomy
```

## Delve Client

The main class for interacting with Delve programmatically.

### Basic Usage

```python
from delve import Delve

# Initialize with defaults
delve = Delve()

# Run taxonomy generation
result = delve.run_sync("data.csv", text_column="text")

# Access results
print(result.taxonomy)
print(result.labeled_documents)
```

### Initialization

```python
delve = Delve(
    model="anthropic/claude-3-5-sonnet-20241022",
    fast_llm="anthropic/claude-3-haiku-20240307",
    sample_size=100,
    batch_size=200,
    use_case="Generate taxonomy for my data",
    output_dir="./results",
    output_formats=["json", "csv", "markdown"],
    verbose=True,
    predefined_taxonomy=None,  # Use existing taxonomy instead of generating
    embedding_model="text-embedding-3-large",
    classifier_confidence_threshold=0.0
)
```

## Configuration Options

<ParamField path="model" type="string" default="anthropic/claude-3-5-sonnet-20241022">
  Main LLM model for taxonomy generation and reasoning.

  ```python
  delve = Delve(model="anthropic/claude-opus-4")
  ```

  Supported models:
  - `anthropic/claude-3-5-sonnet-20241022` (recommended)
  - `anthropic/claude-opus-4` (most capable)
  - `anthropic/claude-3-haiku-20240307` (fastest/cheapest)
  - Any model supported by LiteLLM
</ParamField>

<ParamField path="fast_llm" type="string" default="anthropic/claude-3-haiku-20240307">
  Faster model for document summarization to reduce costs.

  ```python
  delve = Delve(fast_llm="anthropic/claude-3-haiku-20240307")
  ```

  Use a faster, cheaper model for the summarization step.
</ParamField>

<ParamField path="sample_size" type="integer" default="100">
  Number of documents to sample for taxonomy generation.

  ```python
  delve = Delve(sample_size=200)
  ```

  <Tip>
    Larger samples (200-500) produce more comprehensive taxonomies but cost more and take longer. Start with 100 for quick iterations.
  </Tip>
</ParamField>

<ParamField path="batch_size" type="integer" default="200">
  Number of documents per minibatch during iterative clustering.

  ```python
  delve = Delve(batch_size=50)
  ```

  <Info>
    Smaller batches (50-100) produce more refined taxonomies. Larger batches (200-300) are faster but may be less precise.
  </Info>
</ParamField>

<ParamField path="use_case" type="string" default="Generate taxonomy for categorizing document content">
  Custom description of your taxonomy use case.

  ```python
  delve = Delve(
      use_case="Categorize customer feedback by product feature and sentiment"
  )
  ```

  <Tip>
    Providing a specific use case helps guide the model to generate more relevant categories for your domain.
  </Tip>
</ParamField>

<ParamField path="output_dir" type="string" default="./results">
  Directory for saving output files.

  ```python
  delve = Delve(output_dir="./my-results")
  ```

  Creates the directory if it doesn't exist.
</ParamField>

<ParamField path="output_formats" type="list" default="['json', 'csv', 'markdown']">
  List of output formats to generate.

  ```python
  delve = Delve(output_formats=["json", "csv"])
  ```

  Available formats:
  - `json` - Machine-readable taxonomy and labeled documents
  - `csv` - Spreadsheet format for analysis
  - `markdown` - Human-readable reports
</ParamField>

<ParamField path="verbose" type="boolean" default="true">
  Enable progress logging during processing.

  ```python
  delve = Delve(verbose=False)  # Quiet mode
  ```
</ParamField>

<ParamField path="predefined_taxonomy" type="string | list | None" default="None">
  Use an existing taxonomy instead of generating one. Useful when you want to label documents with known categories.

  ```python
  # From a JSON/CSV file
  delve = Delve(predefined_taxonomy="categories.json")

  # Or as a list of dicts
  delve = Delve(predefined_taxonomy=[
      {"id": "1", "name": "Bug", "description": "Bug reports and issues"},
      {"id": "2", "name": "Feature", "description": "Feature requests"},
  ])
  ```

  When provided, Delve skips taxonomy discovery and directly labels documents using the given categories.
</ParamField>

<ParamField path="embedding_model" type="string" default="text-embedding-3-large">
  OpenAI embedding model for classifier training. Used when `sample_size < total documents` to train an efficient classifier for labeling remaining documents.

  ```python
  delve = Delve(embedding_model="text-embedding-3-small")  # Cheaper option
  ```
</ParamField>

<ParamField path="classifier_confidence_threshold" type="float" default="0.0">
  Minimum confidence for classifier predictions. Documents below this threshold fall back to LLM labeling. Set to 0 to use classifier for all documents (no fallback).

  ```python
  delve = Delve(classifier_confidence_threshold=0.8)  # Use LLM for low-confidence docs
  ```
</ParamField>

## Methods

### run_sync()

Synchronous method for taxonomy generation (recommended for most use cases).

```python
result = delve.run_sync(
    data,
    text_column=None,
    id_column=None,
    source_type=None,
    **adapter_kwargs
)
```

<ParamField path="data" type="str | Path | DataFrame" required>
  Data source to process. Can be:
  - Path to CSV file (`"data.csv"`)
  - Path to JSON/JSONL file (`"data.json"`)
  - LangSmith URI (`"langsmith://project-name"`)
  - pandas DataFrame
</ParamField>

<ParamField path="text_column" type="string">
  Column/field name containing text content (required for CSV/DataFrame).

  ```python
  result = delve.run_sync("data.csv", text_column="message")
  ```
</ParamField>

<ParamField path="id_column" type="string">
  Column/field name for document IDs (optional).

  ```python
  result = delve.run_sync(
      "data.csv",
      text_column="text",
      id_column="doc_id"
  )
  ```
</ParamField>

<ParamField path="source_type" type="string">
  Force specific adapter type: `csv`, `json`, `jsonl`, `langsmith`, `dataframe`

  ```python
  result = delve.run_sync(
      "data.txt",
      source_type="json",
      text_field="content"
  )
  ```
</ParamField>

<ParamField path="**adapter_kwargs" type="dict">
  Additional adapter-specific parameters:

  **For JSON:**
  - `json_path` - JSONPath expression for nested data
  - `text_field` - Field name containing text

  **For LangSmith:**
  - `api_key` - LangSmith API key
  - `days` - Days to look back (default: 7)
  - `max_runs` - Maximum runs to fetch
  - `filter_expr` - LangSmith filter expression
</ParamField>

**Returns:** `DelveResult` object with taxonomy, labeled documents, and metadata.

**Example:**

```python
from delve import Delve

delve = Delve(sample_size=150)
result = delve.run_sync(
    "feedback.csv",
    text_column="comment",
    id_column="ticket_id"
)

print(f"Generated {len(result.taxonomy)} categories")
for category in result.taxonomy:
    print(f"- {category.name}: {category.description}")
```

### run()

Asynchronous version of `run_sync()`. Use for async applications.

```python
import asyncio
from delve import Delve

async def main():
    delve = Delve()
    result = await delve.run("data.csv", text_column="text")
    print(result.taxonomy)

asyncio.run(main())
```

### run_with_docs() / run_with_docs_sync()

Process pre-created `Doc` objects directly, useful for programmatic document creation or testing.

```python
from delve import Delve, Doc

docs = [
    Doc(id="1", content="Fix authentication bug"),
    Doc(id="2", content="Add dark mode feature"),
]

delve = Delve(use_case="Categorize software issues")
result = delve.run_with_docs_sync(docs)
# Or async: result = await delve.run_with_docs(docs)
```

## Data Sources

Delve supports multiple input formats. The `source_type` is auto-detected from file extensions, or you can specify it explicitly.

| Format | Extension | Required Parameters |
|--------|-----------|---------------------|
| CSV | `.csv` | `text_column` |
| JSON | `.json` | `text_field` or `json_path` |
| JSONL | `.jsonl` | (auto-extracts text) |
| DataFrame | (in-memory) | `text_column` |
| LangSmith | `langsmith://` URI | `api_key` |

```python
# CSV
result = delve.run_sync("data.csv", text_column="message")

# JSON with JSONPath for nested data
result = delve.run_sync("data.json", json_path="$.messages[*].content")

# pandas DataFrame
result = delve.run_sync(df, text_column="message")

# LangSmith
result = delve.run_sync("langsmith://my-project", api_key="lsv2_...", days=7)
```

## Working with Results

The `DelveResult` object provides access to all outputs:

```python
result = delve.run_sync("data.csv", text_column="text")

# Taxonomy categories
for cat in result.taxonomy:
    print(f"{cat.name}: {cat.description}")

# Labeled documents
for doc in result.labeled_documents:
    print(f"{doc.id} â†’ {doc.category}")

# Metadata and export paths
print(result.metadata)  # {'num_documents': 100, 'num_categories': 5, ...}
print(result.export_paths)  # {'taxonomy': Path(...), 'csv': Path(...), ...}
```

### TaxonomyCategory

| Attribute | Type | Description |
|-----------|------|-------------|
| `id` | str | Unique category identifier |
| `name` | str | Category name |
| `description` | str | Category description |

### Doc (labeled document)

| Attribute | Type | Description |
|-----------|------|-------------|
| `id` | str | Document identifier |
| `content` | str | Original text content |
| `category` | str | Assigned category name |
| `explanation` | str | Why this category was assigned |
| `summary` | str | LLM-generated summary |

## Error Handling

```python
from delve import Delve

try:
    delve = Delve()
    result = delve.run_sync("data.csv", text_column="text")
except ValueError as e:
    # Missing API key, invalid parameters, etc.
    print(f"Configuration error: {e}")
except FileNotFoundError as e:
    # File doesn't exist
    print(f"File not found: {e}")
except Exception as e:
    # Other errors
    print(f"Error: {e}")
```

## Environment Variables

Set these before running your code:

```bash
# Required
export ANTHROPIC_API_KEY="your-anthropic-key"

# Optional
export LANGSMITH_API_KEY="your-langsmith-key"
export LITELLM_LOG="DEBUG"  # Enable detailed logging
```

Or use python-dotenv:

```python
from dotenv import load_dotenv
load_dotenv()

from delve import Delve
# API keys are loaded automatically
```

## Next Steps

<CardGroup cols={2}>
  <Card title="Examples" icon="book" href="/examples">
    See working code examples
  </Card>
  <Card title="CLI Reference" icon="terminal" href="/cli-reference">
    Learn CLI commands
  </Card>
</CardGroup>
